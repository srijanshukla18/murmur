# Murmur

**Live streaming voice-to-text for macOS** â€” speak and watch text appear in real-time, anywhere.

Murmur uses [whisper.cpp](https://github.com/ggerganov/whisper.cpp) with Metal GPU acceleration via embedded Python bindings. Press a hotkey, speak, and watch your words appear live at the cursor. Press again to stop.

## Quick Start

```bash
# Prerequisites
brew install cmake
curl -LsSf https://astral.sh/uv/install.sh | sh

# Setup
git clone https://github.com/srijanshukla/murmur.git
cd murmur
./setup.sh
uv sync

# Run
uv run murmur
```

Press **Right Option (âŒ¥)** to start/stop live transcription.

---

## How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hotkey (Right âŒ¥)                                               â”‚
â”‚       â”‚                                                         â”‚
â”‚       â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ StreamingRecorderâ”‚â”€â”€â”€â”€â–ºâ”‚ Ring Buffer (12s)â”‚                  â”‚
â”‚  â”‚  (16kHz mono)   â”‚     â”‚ + VAD Detection  â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                   â”‚ numpy float32              â”‚
â”‚                                   â–¼ every 500ms                â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚                    â”‚  StreamingTranscriber    â”‚                â”‚
â”‚                    â”‚  (pywhispercpp embedded) â”‚                â”‚
â”‚                    â”‚  Metal GPU acceleration  â”‚                â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                 â”‚ StreamingResult              â”‚
â”‚                                 â–¼                              â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚                    â”‚   StreamingInjector      â”‚                â”‚
â”‚                    â”‚  (diff-based, backspace) â”‚                â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                 â”‚ keystrokes                   â”‚
â”‚                                 â–¼                              â”‚
â”‚                         Focused Application                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Live Streaming Pipeline

1. **Audio Capture**: Ring buffer keeps last 12 seconds, VAD detects speech
2. **Inference**: Every 500ms, whisper runs on the audio window (~60ms on M2)
3. **Stability**: Text is "committed" after 2 stable passes or 600ms silence
4. **Injection**: Diff-based â€” only types changes, uses backspaces for corrections

---

## Features

- **Live streaming** â€” text appears as you speak, not after
- **Embedded whisper.cpp** â€” model stays in GPU memory, no process spawning
- **Metal acceleration** â€” ~60ms inference for 10s audio on Apple Silicon
- **Smart corrections** â€” backspaces and retypes when whisper revises words
- **VAD gating** â€” only runs inference when speech detected
- **Stability tracking** â€” prevents jarring rewrites of committed text

---

## Requirements

### Hardware
- Apple Silicon Mac (M1/M2/M3/M4)
- Microphone

### Software
- macOS 12.0+ (Monterey or later)
- Xcode Command Line Tools: `xcode-select --install`
- cmake: `brew install cmake`
- uv: `curl -LsSf https://astral.sh/uv/install.sh | sh`

### Permissions
- **Microphone**: System Settings â†’ Privacy & Security â†’ Microphone â†’ Enable Terminal
- **Accessibility**: System Settings â†’ Privacy & Security â†’ Accessibility â†’ Enable Terminal

---

## Installation

```bash
# 1. Clone
git clone https://github.com/srijanshukla/murmur.git
cd murmur

# 2. Build whisper.cpp and download model
./setup.sh

# 3. Install Python dependencies
uv sync
```

---

## Usage

```bash
uv run murmur
```

### Workflow

1. Focus any text field (terminal, browser, editor)
2. **Tap Right Option (âŒ¥)** â€” recording starts, you hear "Funk"
3. Speak â€” text appears live as you talk
4. **Tap Right Option (âŒ¥)** â€” final pass runs, you hear "Blow"

### Menu Bar States

| Icon | State | Meaning |
|------|-------|---------|
| ğŸ¤ | Idle | Ready |
| ğŸ”´ | Live | Streaming transcription active |

---

## Configuration

Environment variables or `~/.config/murmur/config.toml`:

```bash
export MURMUR_HOTKEY="alt_r"     # alt_r, alt_l, f8, f9, f10, caps_lock
export MURMUR_MODEL="base.en"   # tiny.en, base.en, small.en, medium.en
export MURMUR_SOUND="true"      # true/false
```

### Models

| Model | Size | Speed | Use Case |
|-------|------|-------|----------|
| tiny.en | ~75MB | Fastest | Quick commands |
| **base.en** | ~150MB | Fast | General use (default) |
| small.en | ~500MB | Medium | Technical dictation |
| medium.en | ~1.5GB | Slower | High accuracy |

---

## Architecture

### Components

| Component | Technology | Purpose |
|-----------|------------|---------|
| Audio | sounddevice + ring buffer | Continuous 16kHz capture |
| VAD | RMS energy threshold | Detect speech vs silence |
| Transcription | pywhispercpp (embedded) | Metal GPU inference |
| Injection | Quartz Events | Diff-based keystroke injection |
| Hotkey | pynput | Global key detection |

### Key Design Decisions

**Why embedded whisper.cpp?**
- Model loads once, stays in GPU memory
- No process spawn overhead (~100ms saved per inference)
- Direct numpy input (no temp files)
- ~60ms inference latency on M2 Pro

**Why streaming instead of batch?**
- Immediate feedback while speaking
- Better UX for long-form dictation
- Corrections happen in real-time

**Why diff-based injection?**
- Whisper can revise recent words as more context arrives
- Instead of clearing and retyping, we compute minimal edits
- Backspaces only the changed portion, types the correction

---

## Troubleshooting

### Text not appearing
Grant accessibility permission to your terminal app.

### No audio captured
Grant microphone permission to your terminal app.

### Transcription hallucinations
Common artifacts like "Thank you." or "[BLANK_AUDIO]" are filtered automatically.

### High latency
Ensure Metal GPU is being used (check logs at `~/Library/Logs/Murmur/`).

---

## Logs

```bash
# View today's logs
cat ~/Library/Logs/Murmur/murmur-$(date +%Y-%m-%d).log

# Tail live
tail -f ~/Library/Logs/Murmur/murmur-$(date +%Y-%m-%d).log
```

---

## License

MIT

## Acknowledgments

- [whisper.cpp](https://github.com/ggerganov/whisper.cpp) â€” Georgi Gerganov
- [pywhispercpp](https://github.com/absadiki/pywhispercpp) â€” Python bindings
- [rumps](https://github.com/jaredks/rumps) â€” macOS menu bar
